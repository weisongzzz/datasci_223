<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Putting a label on things</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-translucentGray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="9a7cd211-31f2-4330-a84d-27123932d201" class="page sans"><header><div class="page-header-icon undefined"><span class="icon">⛳</span></div><h1 class="page-title">Putting a label on things</h1><p class="page-description"></p></header><div class="page-body"><ul id="894ea089-58ff-434f-8684-b81120a32d6b" class="bulleted-list"><li style="list-style-type:disc">Quick example</li></ul><ul id="2639ea1c-cf86-434d-9c63-4a52a7514fe6" class="bulleted-list"><li style="list-style-type:disc">Classification model types and how to evaluate them</li></ul><ul id="98130347-0c53-464e-828a-ed990f3ee8da" class="bulleted-list"><li style="list-style-type:disc">How things can go wrong…</li></ul><ul id="dee6dda2-d0fa-4fa2-abc2-047df0ee7f6d" class="bulleted-list"><li style="list-style-type:disc">… and how to fix it</li></ul><ul id="be6f78d8-7915-45ce-a44b-eda924b3f226" class="bulleted-list"><li style="list-style-type:disc">Hands-on with code</li></ul><h1 id="470d10f6-e25c-4710-8adb-9247d7a46f0f" class="">Preamble</h1><ol type="1" id="aa94ceee-9618-4e83-b177-8fa0e7bebf24" class="numbered-list" start="1"><li>Example analytical technical interview - <a href="https://www.notion.so/Analytics-Technical-Interview-9db281f9f10e49f298f6c6730b1a5cb2?pvs=21"><span class="icon">🧮</span>Analytics Technical Interview</a> </li></ol><ol type="1" id="d499a629-b68f-469c-8c97-0bef47b1fa13" class="numbered-list" start="2"><li>Example interview take-home - <a href="https://github.com/christopherseaman/five_twelve">https://github.com/christopherseaman/five_twelve</a></li></ol><ol type="1" id="7b534597-9a50-4a70-ad78-e06cfca67668" class="numbered-list" start="3"><li>Topics for upcoming lectures and anonymous feedback - <a href="https://forms.gle/dR3b9DhDzQjqVsQf9">https://forms.gle/dR3b9DhDzQjqVsQf9</a></li></ol><ol type="1" id="a8de32bc-2b6d-4923-aae0-50f27a3ceeca" class="numbered-list" start="4"><li>Data sources available on Physionet (some require registration) - <a href="https://physionet.org/about/database/">https://physionet.org/about/database/</a></li></ol><h1 id="f1c39191-249c-449d-80d5-37dc642fc7ca" class="block-color-default"><code>git merge</code> conflicts</h1><ol type="1" id="a28acae0-3de6-4aeb-a03a-1d2c4960f4c4" class="numbered-list" start="1"><li>Working in branches for each exercise</li></ol><ol type="1" id="3444270a-fe43-4f79-a329-b827e010336d" class="numbered-list" start="2"><li>Save to branch and sync (discarding commits)</li></ol><ol type="1" id="2ef03c5d-7f0a-4b9c-9ed5-ae3c75e6e4ea" class="numbered-list" start="3"><li>(<em>Optional</em>) Add files from branch back to <code>main</code> through a Pull Request</li></ol><figure id="374801e8-bab8-49ed-bfb3-b620e8578020" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/git_branches.png"><img style="width:1636px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/git_branches.png"/></a></figure><figure id="38749136-53f2-4ecc-8dcb-a88820aab731"><a href="https://www.atlassian.com/git/tutorials/using-branches/merge-conflicts" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">Git merge conflicts | Atlassian Git Tutorial</div><div class="bookmark-description">What is a git merge conflict? A merge conflict arises when Git cannot automatically resolve code differences between two commits. Learn more here.</div></div><div class="bookmark-href"><img src="https://www.atlassian.com/apple-touch-icon.png" class="icon bookmark-icon"/>https://www.atlassian.com/git/tutorials/using-branches/merge-conflicts</div></div></a></figure><h1 id="43f21fb7-d74d-445e-92cc-6d372500af9b" class="">On the perils of ChatGPT</h1><p id="2f78cb27-7a0f-4fa6-bff2-2e52dba60da4" class="">Not exactly what Linus was talking about, but the quote remains relevant…</p><figure id="000fe29e-36be-4c71-9311-a6ed1bc4ae4c" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/wpvtr5pmskfc1.png.webp"><img style="width:1080px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/wpvtr5pmskfc1.png.webp"/></a></figure><h1 id="9dc22bd5-4cfb-4cbe-b63e-a90c193b764b" class="">🤖 <strong><strong>Accelerate Your Models with GPUs</strong></strong></h1><p id="aedde9ad-8222-448f-bb8f-78cb26a91dea" class="">The models we’ll build today require significant computational power, which might make them run slowly on your laptop. <strong>Don&#x27;t panic!</strong> There are free cloud services you can use to leverage GPU-based computing:</p><ul id="a62e65fe-e582-47bf-b1ce-6aad1841ebe6" class="bulleted-list"><li style="list-style-type:disc"><a href="https://colab.research.google.com"><strong>Google Colab</strong></a> - easiest to use with excellent GitHub integration, but completely public (okay for today, but <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>NEVER USE COLAB WITH SENSITIVE/PHI DATA</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>)</li></ul><ul id="56d9f6ab-db2d-4404-8ad7-b68bf31f8eb7" class="bulleted-list"><li style="list-style-type:disc"><a href="https://www.paperspace.com"><strong>Paperspace</strong></a> - (my weapon of choice) provides customizable private virtual computing with GPUs, but that customization comes at the cost of added complexity. Easy-ish to use, but not as easy as Colab</li></ul><ul id="31ac25e8-9fd7-4523-856c-c8a1db685966" class="bulleted-list"><li style="list-style-type:disc"><strong>UCSF&#x27;s Wynton</strong> - File a ticket with IT to get access</li></ul><figure id="1b729f0a-1b4b-41f3-8216-9abebf971e52"><a href="https://wynton.ucsf.edu/hpc/index.html" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">UCSF Wynton HPC Cluster</div><div class="bookmark-description">2023-07-21: Rocky 8: Wynton will migrate from CentOS 7 to Rocky 8 at
the end of October 2023. To prepare for this, we have made one non-PHI
and one PHI development node available for all users, together with
six compute nodes.</div></div><div class="bookmark-href"><img src="https://wynton.ucsf.edu/hpc/assets/ico/favicon.ico?" class="icon bookmark-icon"/>https://wynton.ucsf.edu/hpc/index.html</div></div></a></figure><h2 id="450a8058-7192-4525-ad21-632bf41b3209" class="">Example speed-up</h2><p id="b5683204-3842-4e92-abaa-5c4e74c646ad" class="">From training the “Which animal is this” in the “Hands-on practice” section below</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="8e537f13-b9df-4099-afd4-5ea314751b57" class="code"><code class="language-Shell"># 2018 Macbook Pro
Epoch 1/25
63/63 [==============================] - 1177s 18s/step - loss: 0.7522 - accuracy: 0.5904 - val_loss: 0.8942 - val_accuracy: 0.4998

# Google Colab GPU
Epoch 1/25
63/63 [==============================] - 150s 2s/step - loss: 0.7323 - accuracy: 0.6080 - val_loss: 0.9307 - val_accuracy: 0.4998

# Paperspace RTX-5000
Epoch 1/25
63/63 [==============================] - 64s 989ms/step - loss: 0.7348 - accuracy: 0.5988 - val_loss: 0.8696 - val_accuracy: 0.4998</code></pre><h1 id="f8b028d3-b8df-47d0-beda-a9bc4f6664b3" class="">💥 Crash course in classification</h1><figure id="7a06127c-680d-4161-8279-936ec1053868" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/xkcd_classification.png"><img style="width:450px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/xkcd_classification.png"/></a></figure><p id="e40e3190-a12a-4657-93f7-0391b72ccbf6" class="">The building blocks of ML are algorithms for <strong>regression</strong> and <strong>classification:</strong></p><ul id="e784537a-3f6c-429d-af5b-2ce38a0d1084" class="bulleted-list"><li style="list-style-type:disc"><strong>Regression</strong>: predicting continuous quantities</li></ul><ul id="f6c8396d-35a9-467e-b1b5-b4e57fd6b8e7" class="bulleted-list"><li style="list-style-type:disc"><strong>Classification</strong>: predicting <em>discrete class labels </em>(categories)</li></ul><h2 id="31b4ebfd-9f4c-4e1c-b659-0df102c4662e" class=""><strong>Classification methods</strong></h2><p id="4e088b51-275b-4834-93c2-517ae94b8057" class="">Classification algorithms aim to learn a function that maps input features to class labels. The most popular classification methods are:</p><ul id="3c5e8d24-9714-4529-b038-6f79ffc0411c" class="bulleted-list"><li style="list-style-type:disc"><strong>Logistic Regression</strong>: a simple linear model that models the probability of each class based on the input features. It&#x27;s easy to interpret and works well for binary classification problems.</li></ul><ul id="89caeb90-4c74-4f47-bf20-46606a0a0628" class="bulleted-list"><li style="list-style-type:disc"><strong>Decision Trees</strong>: builds a tree-like model that maps features to class labels. It&#x27;s easy to interpret, but prone to overfitting.</li></ul><ul id="ebaf1577-3d3a-4628-a296-ecd853737a40" class="bulleted-list"><li style="list-style-type:disc"><strong>Random Forest</strong>: an ensemble model that builds multiple decision trees and averages their predictions. It&#x27;s more accurate than a single decision tree and less prone to overfitting.</li></ul><ul id="bfab3b14-652b-437f-bba5-e9a9405d22a4" class="bulleted-list"><li style="list-style-type:disc"><strong>Support Vector Machines (SVM)</strong>: constructs a hyperplane that separates the classes with the maximum margin. It works well for high-dimensional data.</li></ul><ul id="4190acde-6bab-4581-8173-637b2643b509" class="bulleted-list"><li style="list-style-type:disc"><strong>Naive Bayes</strong>: applies Bayes&#x27; theorem with strong independence assumptions between the features. It&#x27;s easy to train and performs well for small datasets.</li></ul><ul id="d73df33b-431e-4e86-a0b5-9c9c1ce38f7d" class="bulleted-list"><li style="list-style-type:disc"><strong>Neural Networks</strong>: models the mapping between inputs and outputs using an interconnected network of nodes. It can capture complex, non-linear relationships between features.</li></ul><p id="a6fe3a3c-007d-4c76-971d-bb875404d3a6" class="">
</p><ul id="87d2231a-2c74-4620-823f-11a2f6d432e2" class="toggle"><li><details open=""><summary>Some links to dive deeper:</summary><ul id="8d754a68-5461-438c-97d9-f6606991fe93" class="bulleted-list"><li style="list-style-type:disc">A nice tour of methods: <a href="https://github.com/bagheri365/ML-Models-for-Classification"><strong>https://github.com/bagheri365/ML-Models-for-Classification</strong></a></li></ul><ul id="5c2726ac-0b95-443e-8519-ed2c8e62d249" class="bulleted-list"><li style="list-style-type:disc"><a href="https://www.kaggle.com/code/nandita711/cancer-classification-eda-pca-random-forest"><strong>Cancer classification</strong></a> (Kaggle)</li></ul><ul id="23e8cf75-6472-4b2b-8fb5-5fac8409b44d" class="bulleted-list"><li style="list-style-type:disc"><a href="https://www.frontiersin.org/articles/10.3389/fcimb.2022.819267/full"><strong>Comparison of XGBoost, Random Forest, and Nomograph for Prediction of Disease Severity</strong></a></li></ul><ul id="a256c587-e4bc-4c97-ba71-a214b06497d2" class="bulleted-list"><li style="list-style-type:disc"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6963807/"><strong>Prediction Method for Hypertension</strong></a> (Diagnostics Journal)</li></ul><ul id="a898102f-c548-430f-a576-2e58bc475ad2" class="bulleted-list"><li style="list-style-type:disc"><a href="https://towardsai.net/p/l/a-guide-to-predictive-lead-scoring-using-machine-learning"><strong>Guide to Predictive Lead Scoring using ML</strong></a> (Towards AI)</li></ul><ul id="e1bca963-aaa5-4253-8f4a-f7871b9ea835" class="bulleted-list"><li style="list-style-type:disc"><a href="https://towardsdatascience.com/a-true-end-to-end-ml-example-lead-scoring-f5b52e9a3c80"><strong>True end-to-end ML example: Lead Scoring</strong></a> (Towards Data Science)</li></ul></details></li></ul><h2 id="7fb7a295-2234-4773-a34c-752253d9fd4e" class="">Model evaluation</h2><p id="480a897d-7add-45e7-ac46-ea8169cd24b0" class="">There are many more classification approaches than data scientists, so choosing the best one for your application can be daunting. Thankfully, all of them output predicted classes for each data point. We can use this similarity to define objective performance criteria based on how often the predicted class matches the underlying truth.</p><p id="1647cc77-1bc8-4fa3-86f3-f117c8675ba9" class="">I get in trouble with the data science police if I don’t include something about confusion matrices:</p><figure id="8359de24-9939-4a54-ab8f-4e65bfcf1053" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/evaluation.png"><img style="width:754px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/evaluation.png"/></a></figure><ul id="10b074df-70bf-44f9-a187-27a750257979" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong><strong><strong><strong>Precision</strong></strong></strong></strong></strong></strong></strong></strong></strong> (Positive Predictive Value) = <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{TP}{TP + FP}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">FP</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><span>﻿</span></span><blockquote id="e17e6a82-db43-46d5-9bce-141081a547bb" class=""><em>How well it performs when it predicts positive</em></blockquote></li></ul><ul id="09b840cf-efc6-4699-b73d-416a8fa1ad6e" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong>Recall</strong></strong></strong></strong></strong></strong> (Sensitivity, True Positive Rate) = <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>P</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{TP}{TP+FN}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">FN</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><span>﻿</span></span><blockquote id="7c4add1b-9a74-461c-add1-c1c80dcedd21" class=""><em>How well it performs among actual positives</em></blockquote></li></ul><ul id="453878c9-5951-41dc-bbd8-171abde07c10" class="bulleted-list"><li style="list-style-type:disc"><strong>Accuracy </strong>=<strong> </strong><strong><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mo stretchy="false">(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo stretchy="false">)</mo></mrow><mrow><mo stretchy="false">(</mo><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{(TP+TN)}{(TP+FP+FN+TN)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.53em;vertical-align:-0.52em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.01em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">FP</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">FN</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">TN</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.485em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">TN</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.52em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><span>﻿</span></span></strong><blockquote id="88249192-cdc9-4133-b8d5-df1262a1ee07" class=""><em>How well it performs among all known classes</em></blockquote></li></ul><ul id="f66d83dd-65c4-4ecd-84ab-aa41d504f7f0" class="bulleted-list"><li style="list-style-type:disc"><strong><strong>F1 score</strong></strong> = 2(Recall * Precision)/(Recall + Precision)<blockquote id="494f67eb-837b-4796-b586-8b505c593fc8" class=""><em>Balanced score for overall model performance</em></blockquote></li></ul><ul id="0762b1bc-5463-485f-9514-83f88df7d99c" class="bulleted-list"><li style="list-style-type:disc"><strong><strong>Specificity </strong></strong>(Selectivity, True Negative Rate) = <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>T</mi><mi>N</mi></mrow><mrow><mi>T</mi><mi>N</mi><mo>+</mo><mi>F</mi><mi>P</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{TN}{TN + FP}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">TN</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.13889em;">FP</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">TN</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><span>﻿</span></span><blockquote id="7ccf3273-2244-4b6d-9e8a-82d4cbcfb428" class=""><em>Similar to</em> <strong><strong><strong><strong><strong><strong>Recall</strong></strong></strong></strong></strong></strong>, <em>how well it performs among actual negatives</em></blockquote></li></ul><ul id="7ab709d4-997a-4fd8-9c97-30731bcfa2c7" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Miss Rate</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> (False Negative Rate) = <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>F</mi><mi>N</mi></mrow><mrow><mi>T</mi><mi>P</mi><mo>+</mo><mi>F</mi><mi>N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{FN}{TP + FN}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2757em;vertical-align:-0.4033em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8723em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">TP</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.10903em;">FN</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">FN</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span><span>﻿</span></span><blockquote id="125722c3-d18e-46f8-9622-638aa4f8998c" class=""><em>Proportion of positives that were incorrectly classified, good measure when missing a positive has a high cost</em></blockquote></li></ul><ul id="c27e191a-48c6-4b58-95d4-e324b3d76c92" class="bulleted-list"><li style="list-style-type:disc"><strong>Receiver-Operator Curve (ROC Curve) and Area Under the Curve (AUC)</strong><blockquote id="d43de496-5053-4aee-ad3e-f260b353faac" class=""><em>Plot the True Positive vs. False Positive rates, which provides a scale-invariant measure of performance. A random model on balanced class data will have a score of 0.5, while a perfect model will always have a score of 1</em> </blockquote></li></ul><figure id="bae6acfb-d749-4028-b9bd-132373d6eb40" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/auroc.png"><img style="width:1200px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/auroc.png"/></a></figure><ul id="c2a1469c-e757-4c6c-a05b-f01fd55039a3" class="bulleted-list"><li style="list-style-type:disc"><a href="https://www.edlitera.com/en/blog/posts/evaluating-classification-models">How to evaluate classification models</a> (edlitera)</li></ul><h2 id="da6f0368-4415-4e4e-af9a-d243fa0f59a6" class="">Supervised vs. unsupervised</h2><p id="cdebcb4b-f26d-42ee-a417-3612e34c5745" class="">There are two-ish overarching categories of classification algorithms: <strong>supervised</strong> and <strong>unsupervised</strong>. There are many possible approaches in each category, and some that work well in both (deep learning, for example).</p><ul id="ce23a139-3f7c-4929-a3d1-ff60610b1dd7" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Supervised </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>- uses labeled datasets with known classes for the data points</li></ul><ul id="3ff6c293-f984-4c31-9a53-dd107af92d09" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Unsupervised</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> - uses unlabeled data to uncover organizational patterns</li></ul><ul id="44773f2c-d496-4713-90ab-44e7664ac9f3" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Semi-supervised</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> - some data with labels is used to extract relevant features, while others without can amplify that signal; e.g., medical images (x-ray, CT)</li></ul><figure id="8f543226-2743-4ac1-b605-a75f43d412f7" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/unsupervised.png"><img style="width:600px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/unsupervised.png"/></a></figure><h2 id="40b32867-7ff7-4d9e-a8c5-f054c37517b9" class="">Supervised models</h2><p id="3c6b9bc8-d062-4822-a21e-fb1dfd536fd1" class="">To fairly evaluate each model, we must <strong><strong><strong><strong>test</strong></strong></strong></strong> its performance on different data than it was <strong><strong><strong><strong><strong><strong>train</strong></strong></strong></strong></strong></strong>ed on. So we split our dataset into two partitions: <strong><strong><strong><strong>test</strong></strong></strong></strong> and <strong><strong>train</strong></strong>:</p><ul id="3884addc-3294-424a-8989-b865f869a2ab" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong>Train</strong></strong></strong></strong></strong> - the model is built using this data, which includes class labels</li></ul><ul id="f84b6d88-2c0a-4307-bf64-c64ceba9071c" class="bulleted-list"><li style="list-style-type:disc"><strong><strong>Test</strong></strong> -  the model is tested using this data, withholding class labels</li></ul><h3 id="9f5982b2-5f1a-4494-8909-58e1033606f9" class="">Quick supervised model review</h3><p id="b77cb9fe-21ce-4ecb-ac8d-d111843b8b3b" class="">Let’s look at a few tools that you should get a lot of use out of:</p><ul id="5a439f07-5e7d-49f0-bc16-1a349a05939d" class="bulleted-list"><li style="list-style-type:disc"><strong>Logistic Regression </strong>shouldn’t be overlooked! It’s not as new as some other models, but it’s simple and works.</li></ul><ul id="17d92db4-80d5-41b0-9809-017908bb6389" class="bulleted-list"><li style="list-style-type:disc"><strong>Random Forest</strong> is an ensemble model that makes many decision trees using bagging, then takes a simple vote across them to assign a class</li></ul><ul id="ee484868-d55d-4e5f-b304-06ede7b13f5e" class="bulleted-list"><li style="list-style-type:disc"><strong>XGBoost</strong> is another ensemble and arguably the most widely used (and useful) algorithm in tabular ML (it can do regression, classification, and julienne fries!)</li></ul><ul id="8d645932-fa7b-4190-a144-049c3f115f1c" class="bulleted-list"><li style="list-style-type:disc"><strong>Deep Learning</strong> uses artificial neural networks with multiple layers to learn complex patterns from data. These models have performed well in a variety of tasks: image recognition, speech recognition, and natural language processing.<p id="8fa29a9b-d277-49dc-913b-ceda06d957cd" class=""><em><em><em><em><em><em><em><em><em><em><em><em><em><em><em><em><em><em><em><em><em>Deep Learning models may also be used in unsupervised settings</em></em></em></em></em></em></em></em></em></em></em></em></em></em></em></em></em></em></em></em></em></p></li></ul><h3 id="2213ebfd-5430-4c51-9d5a-661ec76470cb" class="">Logistic regression</h3><p id="aba242c9-2699-4c6b-bde1-ab0df5807f10" class="">Logistic regression works similarly to linear regression but uses a sigmoid curve that squeezes our straight line into an S-curve.</p><figure id="c5ca0162-5a56-480a-a63d-422af522a75b" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/lin_vs_log.png"><img style="width:725px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/lin_vs_log.png"/></a></figure><p id="708807ae-d685-4ec1-a56d-e8a85df9ff2e" class="">Additionally, it uses <strong><strong><strong><strong><strong><strong><strong><strong>log loss</strong></strong></strong></strong></strong></strong></strong></strong> in place of our usual mean-squared error cost function. This provides a convex curve for approximating variable weights using gradient descent.</p><figure id="2edc934f-9cfe-4de8-af59-842b2c5ec94c" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/approx_optimization.png"><img style="width:618px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/approx_optimization.png"/></a></figure><ul id="c6380f18-687f-460a-a427-9a60a7837f35" class="bulleted-list"><li style="list-style-type:disc"><a href="https://christophm.github.io/interpretable-ml-book/logistic.html">Logistic regression</a> (interpretable ml)</li></ul><ul id="76244436-9d45-4c0e-9770-3b657becfa9e" class="bulleted-list"><li style="list-style-type:disc"><a href="https://www.kaggle.com/general/192255">Logistic Regression using Gradient descent</a> (kaggle)</li></ul><h3 id="61272d30-2776-4b24-815d-139d0913cf32" class="">Random forest</h3><p id="8f59340c-f24a-4e76-853f-f84bc7241373" class="">Each of the steps can be tweaked, but the general flow goes:</p><ol type="1" id="1ce280f6-9cbe-40ba-be02-5ca98d483770" class="numbered-list" start="1"><li><strong>Bagging </strong>- create <em>k</em> random samples from the data set</li></ol><ol type="1" id="b034631b-1fae-4fcc-b02c-912309177344" class="numbered-list" start="2"><li><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Grow trees</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> - individual decision trees are constructed by choosing the best features and cutpoints to separate the classes</li></ol><ol type="1" id="e1d4119d-2702-4e11-a739-546824a482b5" class="numbered-list" start="3"><li><strong><strong><strong><strong><strong><strong><strong><strong>Classify</strong></strong></strong></strong></strong></strong></strong></strong> - instances are run through all trees and assigned a class by majority vote</li></ol><figure id="9795af29-83d7-48c6-bdc2-f002e1ca49a6" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/bagging.png"><img style="width:1400px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/bagging.png"/></a></figure><h3 id="1e0611cb-a84a-400b-8d6a-a56567a7d4a4" class="">XGBoost</h3><p id="49716f90-a8d4-411f-82c1-d2b33a96c498" class="">XGBoost stands for <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Extreme Gradient Boosting</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>. Like other tree algorithms, XGBoost considers each instance with a series of <code>if</code> statements, resulting in a leaf with associated class assignment scores. Where XGBoost differs is that it uses gradient boosting to focus on weak-performing areas of the previous tree.</p><ul id="2112d929-2704-44a0-9174-b4cdb249c1b6" class="bulleted-list"><li style="list-style-type:disc"><strong>Boosting </strong>- sequentially choosing models by minimizing errors from previous models while increasing the influence of high-performing models; i.e., each model tries to improve where the last was wrong</li></ul><ul id="31842ebe-1894-4d28-a504-b502d39a7d36" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Gradient boosting</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> - a stagewise additive algorithm sequentially adding trees to improve performance measured by a <strong>loss function</strong> until some threshold is met. It’s a greedy algorithm prone to overfitting but often proves useful when focused on poor-performing areas</li></ul><figure id="2b3c4eca-2df9-4d14-ad1c-04b8504bd998" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/xgboost.png"><img style="width:788px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/xgboost.png"/></a></figure><ul id="3e86fcc6-85c2-4c5c-beed-b3db3e0ff2dd" class="bulleted-list"><li style="list-style-type:disc"><a href="https://medium.com/geekculture/xgboost-versus-random-forest-898e42870f30">XGBoost vs Random Forest</a> (geek culture)</li></ul><ul id="38a675e3-01b1-4ebb-b525-3e9364187211" class="bulleted-list"><li style="list-style-type:disc"><a href="https://towardsdatascience.com/interpretable-machine-learning-with-xgboost-9ec80d148d27">Interpretable machine learning with XGBoost</a> (towardsdatascience)</li></ul><h2 id="ec4a918d-b19a-48c2-8caf-915daa618c53" class="">Deep learning</h2><p id="1794e78b-eee8-46e2-bbd3-fdc11369339f" class=""><strong>Deep learning</strong> is a subfield of machine learning that uses artificial neural networks with multiple layers to learn complex patterns from data. These models use back-propagation to adjust the weights in each layer during training, allowing them to model very large and complex datasets.</p><p id="50fda539-c7cf-46ab-8069-c39ad6fd15f8" class="">Deep learning models are especially useful for handling large datasets with high dimensionality, and they can be used for both supervised and unsupervised learning tasks. However, they often require a large amount of data and computation power to train effectively. </p><p id="c6972874-85b5-47fa-a83c-d1a10e23d89d" class="">These models have performed well in a variety of tasks such as image recognition, speech recognition, and natural language processing.</p><ul id="4b736ea2-5ac6-45e7-b894-6f6359bfad20" class="bulleted-list"><li style="list-style-type:disc"><strong>Artificial neural networks</strong> - a computational model inspired by biological neural networks that learn by adjusting the weights between neurons through training data</li></ul><ul id="162a7a1e-7fea-4605-b9f3-71350bc1aea7" class="bulleted-list"><li style="list-style-type:disc"><strong>Deep neural networks</strong> - an artificial neural network with more than one hidden layer; these additional layers enable the model to learn more complex patterns from the input data</li></ul><ul id="ff98e3d9-842a-40ff-90e9-f35672775721" class="bulleted-list"><li style="list-style-type:disc"><strong>Convolutional neural networks</strong> - a type of deep neural network designed for image and video recognition tasks that use convolutional layers to detect features in the input data</li></ul><ul id="5dea4059-4611-44b7-ae1e-323c80b6eea5" class="bulleted-list"><li style="list-style-type:disc"><strong>Recurrent neural networks</strong> - a type of deep neural network designed for sequence data that uses recurrent connections to remember previous inputs and outputs</li></ul><ul id="903e1f54-9f5e-423a-8fa3-6a24a557cf65" class="bulleted-list"><li style="list-style-type:disc"><strong>Popular frameworks</strong> - TensorFlow, PyTorch, and Keras are commonly used deep learning frameworks for building and training deep learning models. Each framework maintains a list of tutorials/examples for getting started (and plenty more on the web + youtube):<ul id="f26ad8a1-2841-43d7-8493-1f7b1bf4e776" class="bulleted-list"><li style="list-style-type:circle"><strong>Keras</strong><ul id="fbb99b75-3b8e-4082-93f1-38652b2be991" class="bulleted-list"><li style="list-style-type:square"><a href="https://keras.io/getting_started/">https://keras.io/getting_started/</a> </li></ul><ul id="72bda245-c339-4523-8673-0c34e9d46c35" class="bulleted-list"><li style="list-style-type:square"><em>Deep Learning with Python </em>(free pdf)</li></ul></li></ul><ul id="5e8483bd-3854-45cb-8999-b05b0eebba29" class="bulleted-list"><li style="list-style-type:circle"><strong>Pytorch</strong><ul id="8502e2e2-b823-48a5-84e7-dbbadfa62a23" class="bulleted-list"><li style="list-style-type:square"><a href="https://pytorch.org/tutorials/">https://pytorch.org/tutorials/</a></li></ul><ul id="c60916f1-1de8-4c7d-b3e5-8a3e59f2ebe9" class="bulleted-list"><li style="list-style-type:square"><a href="https://github.com/ritchieng/the-incredible-pytorch">https://github.com/ritchieng/the-incredible-pytorch</a></li></ul></li></ul><ul id="576e676c-d4e4-42bb-8357-3fd270587cb8" class="bulleted-list"><li style="list-style-type:circle"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Tensorflow</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong><ul id="28438923-a79f-4287-957a-42a73ce9cf13" class="bulleted-list"><li style="list-style-type:square"><a href="https://www.tensorflow.org/tutorials/quickstart/beginner">https://www.tensorflow.org/tutorials/quickstart/beginner</a></li></ul><ul id="41501605-7d77-4bd1-a17a-52fc9d95f779" class="bulleted-list"><li style="list-style-type:square">Tensorflow <a href="https://github.com/tensorflow/examples">https://github.com/tensorflow/examples</a></li></ul></li></ul><ul id="21d36f3f-4487-41f1-a33d-dcec5bb8d62d" class="bulleted-list"><li style="list-style-type:circle"><strong><strong><strong>JAX</strong></strong></strong><ul id="9d93c3e9-79c2-45fc-851f-4d4bb8057f9e" class="bulleted-list"><li style="list-style-type:square"><a href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html">https://jax.readthedocs.io/en/latest/notebooks/quickstart.html</a></li></ul><ul id="8158b5a9-502e-4b0b-8a2b-39024a1dbe53" class="bulleted-list"><li style="list-style-type:square"><a href="https://github.com/gordicaleksa/get-started-with-JAX">https://github.com/gordicaleksa/get-started-with-JAX</a></li></ul></li></ul></li></ul><h2 id="d439f7af-bc0e-44e3-b851-43bf33a8f5de" class="">Unsupervised models</h2><p id="bb9d819d-851b-4901-8e94-b80ee060e2a5" class="">Unsupervised models come in a few flavors: </p><ul id="862d4fc5-7b98-4aea-a5da-d9e71fe89caf" class="bulleted-list"><li style="list-style-type:disc"><strong>Clustering</strong>: grouping points based on similarities/differences; e.g., proximity and separability of data, market segmentation, image compression<ul id="23aadc2b-1d1d-43b5-8163-9ae396f485d7" class="bulleted-list"><li style="list-style-type:circle">K-means (and Fuzzy K-means)</li></ul><ul id="2ee68c63-b923-4c95-bb7e-b85b9dd7dbaf" class="bulleted-list"><li style="list-style-type:circle">Hierarchical clustering (e.g., BIRCH)</li></ul><ul id="3ba1aa8e-30e8-4d2f-87c3-052e05639556" class="bulleted-list"><li style="list-style-type:circle">Gaussian mixture</li></ul><ul id="9f79a643-525e-48fe-be7c-df625f8600fd" class="bulleted-list"><li style="list-style-type:circle">Affinity Propagation</li></ul><ul id="528af020-52a3-4e28-95b0-f065a61fe0bd" class="bulleted-list"><li style="list-style-type:circle">Anomaly detection<ul id="6f51927c-86bb-423e-8e19-015363cb5be5" class="bulleted-list"><li style="list-style-type:square">Isolation Forest</li></ul><ul id="afb59d2a-69c1-4b66-be3f-e01f054eea98" class="bulleted-list"><li style="list-style-type:square">Local Outlier Factor</li></ul><ul id="76c5d356-d29d-4941-8d05-5d26aeeeacca" class="bulleted-list"><li style="list-style-type:square">Min Covariant Determinant</li></ul></li></ul></li></ul><ul id="e3d621ac-1794-4d2e-bf48-9055c737ad40" class="bulleted-list"><li style="list-style-type:disc"><strong>Association</strong>: reveals relationships between variables; e.g., A goes up and B goes down, people who buy X also buy Y<ul id="55b67d78-7658-4303-b1be-ae6b7ee7e28f" class="bulleted-list"><li style="list-style-type:circle">Apriori</li></ul><ul id="b5baa467-afad-4f34-b573-d535d599bf51" class="bulleted-list"><li style="list-style-type:circle">Equivalence Class Transformation (eclat)</li></ul><ul id="4dfea45b-0530-4103-ba13-76fa8670e400" class="bulleted-list"><li style="list-style-type:circle">Frequent-Pattern (F-P) Growth</li></ul></li></ul><ul id="046bdd70-c8f3-4600-bfb9-1266769a9916" class="bulleted-list"><li style="list-style-type:disc"><strong>Dimensionality</strong> reduction: reduces the inputs to a smaller size while attempting to preserve predictive power; e.g., removing noise and collinearity<ul id="f2bcb82e-480c-4371-a82d-69d4875c4613" class="bulleted-list"><li style="list-style-type:circle">Principal Component Analysis</li></ul><ul id="5e2d292c-b901-412d-afff-69d23b8825fb" class="bulleted-list"><li style="list-style-type:circle">Manifold Learning — LLE, Isomap, t-SNE</li></ul><ul id="44167b68-44e5-4f5b-8f55-6555663fe55d" class="bulleted-list"><li style="list-style-type:circle">Autoencoders</li></ul></li></ul><p id="2d369779-8b5a-4d88-b2b5-393e30f5268b" class="">
</p><p id="e0b0ec79-de79-4985-bfcc-07d9977e58f9" class="">Links to learn more:</p><ul id="81791283-b207-4a24-ab19-bddb9485a12b" class="bulleted-list"><li style="list-style-type:disc">Unsupervised Learning: Algorithms and Examples (<a href="https://www.altexsoft.com/blog/unsupervised-machine-learning/">altexsoft</a>)</li></ul><h2 id="2856552f-f0a1-4213-88cc-77dadec7077f" class="">Topics cut for time</h2><ul id="1dcc1225-22ec-49f8-aa24-5edf333ed2da" class="bulleted-list"><li style="list-style-type:disc">Bias and fairness: How models can produce biased results and unfairly disadvantage certain groups of people. This could include a discussion on how to detect and mitigate bias in classification models.</li></ul><ul id="0b059529-bf30-41ed-a3f7-822f715f60a0" class="bulleted-list"><li style="list-style-type:disc">Interpretability and explainability: How to interpret and explain the decisions made by classification models. This could include a discussion on the methods used to create interpretable models, such as decision trees and rule-based systems.</li></ul><ul id="9b920a96-6d48-4202-b90e-71d724576869" class="bulleted-list"><li style="list-style-type:disc">Handling imbalanced data: Techniques for dealing with datasets where one class is significantly more prevalent than others. This could include a discussion on methods such as oversampling, undersampling, and class weighting.</li></ul><ul id="0711aa38-6799-46b4-a096-eb4be21a5d40" class="bulleted-list"><li style="list-style-type:disc">Transfer learning: How to leverage pre-trained models for classification tasks where limited labeled data is available. This could include a discussion on fine-tuning pre-trained models and using transfer learning to improve classification performance.</li></ul><h1 id="4162531b-f9c9-46de-8dd3-e1f384f21c2f" class="">📉 How models fail</h1><h2 id="b24801f1-3543-4991-b893-6bde9b258a68" class="">Labeling</h2><p id="090d91a8-651e-42a8-b384-22b46f2c35fd" class="">Oh, labeling…</p><p id="e1f1e790-fbb0-4555-85d7-ee77135032b3" class="">Labeling issues can arise when the data is not labeled correctly or consistently, which can lead to biased or inaccurate models. Examples of labeling issues include:</p><ul id="d3b687f1-f305-45c3-8612-cfc04eb9176d" class="bulleted-list"><li style="list-style-type:disc"><strong>Mislabeling</strong>: Labels that are assigned to data points are incorrect.</li></ul><ul id="10247d7b-9a14-477e-9e74-e7e1fdddba03" class="bulleted-list"><li style="list-style-type:disc"><strong>Ambiguous labeling</strong>: Labels that are assigned to data points are not clear or specific.</li></ul><ul id="597a6d9b-e201-4c4e-ad2d-92f7854e9a9b" class="bulleted-list"><li style="list-style-type:disc"><strong>Inconsistent labeling</strong>: Labels that are assigned to similar data points are not the same</li></ul><h2 id="03ab7564-32c0-47f2-8ec2-10f70d2d940e" class="">Fit</h2><p id="0712658c-9a38-4f30-b6b9-9a46ebf27b06" class="">A model may fail to fit the data in one of two ways: under-fitting or over-fitting:</p><ul id="22332a45-7f3d-45fb-8304-1509a7f2c552" class="bulleted-list"><li style="list-style-type:disc"><strong>Under-fitting</strong>: The model fails to capture the the differences between the classes. The model may be too simple, lack the necessary features, or the classes may not easily divide based on existing data.</li></ul><ul id="06081fe3-2be3-47ff-8118-3d16a3a6cb45" class="bulleted-list"><li style="list-style-type:disc"><strong>Over-fitting</strong>: The model fits the training data too closely, leading to poor generalization. This can be the case when the model is overly complex or the data may have “too many features”.<blockquote id="a71f7d42-3720-4e98-bc50-87a5b1c3aebc" class=""><strong>Note</strong>: <em>With enough variables you can build a perfect predictor for anything (at least in the training set). That doesn’t mean the model will perform well in the wild</em></blockquote></li></ul><h2 id="0b859a8e-ec42-4b45-a79a-804ba64f6823" class=""><strong>Dataset Shift</strong></h2><p id="b8e959c2-2572-4b33-854e-8ffbd893985f" class="">Dataset shift occurs when the distribution of the data changes between the training and test sets. Dataset shift can be divided into three types:</p><ol type="1" id="d0be6635-1cec-43bb-88fe-db7056beb131" class="numbered-list" start="1"><li><strong>Covariate Shift</strong>: A change in the distribution of the independent variables between the training and test sets.</li></ol><ol type="1" id="8bb9e7b9-f9b0-4651-af63-41c6e4465ef6" class="numbered-list" start="2"><li><strong>Prior Probability Shift</strong>: A change in the distribution of the target variable between the training and test sets.</li></ol><ol type="1" id="16f4ee64-fa2d-4d49-8088-910ad5a9d137" class="numbered-list" start="3"><li><strong>Concept Shift</strong>: A change in the relationship between the independent and target variables between the training and test sets.</li></ol><p id="589d4e34-4da0-45d7-a2c8-95f1e981bb35" class="">See: <a href="https://d2l.ai/chapter_linear-classification/environment-and-distribution-shift.html">https://d2l.ai/chapter_linear-classification/environment-and-distribution-shift.html</a></p><h2 id="44b8abac-0f96-4a5d-8250-0c0fe3336465" class="">Simpson’s Paradox</h2><p id="b5a256d8-40bd-428f-9edf-5f17cf33fb76" class=""><strong>Simpson&#x27;s paradox</strong> occurs when a trend appears in several different groups of data, but disappears or reverses when these groups are combined. It is a common problem in statistics and machine learning that can occur when there are confounding variables that affect the relationship between the independent and dependent variables.</p><figure id="3037c97d-3ed6-4eec-8851-535c67e7b034" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/simpsons_paradox.png"><img style="width:813px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/simpsons_paradox.png"/></a></figure><h2 id="533a543c-5bed-4dc4-98e1-87f9cc0f8414" class="">Troublesome classes</h2><p id="537b1754-97ac-4d9f-89eb-4e08fde27ec8" class="">Certain classes or categories in a dataset may be more difficult to classify accurately than others. This can be due to imbalanced class distribution, noisy data, or other factors. Identifying and addressing troublesome classes is an important step in building effective classification models.</p><p id="e1381b2f-aade-4865-a870-15c654dd348c" class="">Additional topics that could be added to this section include:</p><ul id="2ef81931-81c8-47d7-8d15-69e3785f17c7" class="bulleted-list"><li style="list-style-type:disc">Bias and fairness in classification models</li></ul><ul id="dcbf6332-c886-4bc5-9439-ec22a75e057a" class="bulleted-list"><li style="list-style-type:disc">Lack of interpretability in black-box models</li></ul><ul id="c17427cd-24d3-47ab-abe7-ba16bdd0c490" class="bulleted-list"><li style="list-style-type:disc">Adversarial attacks and robustness of classification models</li></ul><ul id="054dbeee-7e98-4dbe-8dfa-db65ef5db994" class="bulleted-list"><li style="list-style-type:disc">Transfer learning and domain adaptation in classification models</li></ul><ul id="820cc4e9-c3fe-4050-9c0f-795e90be3520" class="bulleted-list"><li style="list-style-type:disc">Active learning and semi-supervised learning for classification.</li></ul><figure id="9e77b02a-473f-4615-82dc-135bd9535b0d" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/confused_classes.png"><img style="width:679px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/confused_classes.png"/></a></figure><h1 id="56ae9202-add4-4136-b2d9-0a12d834d01c" class="">🎛️ Model tuning (teaser)</h1><p id="e809641e-4eb5-4279-bb9b-9da9bf20f18e" class="">Fixing poor-performing models can take many forms</p><ul id="43d3f44f-aeb4-4c7a-979e-306b1f701cb5" class="bulleted-list"><li style="list-style-type:disc">Additional data or data preparation<ul id="6b8d5357-c4d3-4a4d-afda-68a5f2125f38" class="bulleted-list"><li style="list-style-type:circle"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>FEATURE ENGINEERING!</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong> (worth a whole lecture or even a course)</li></ul></li></ul><ul id="75b93fcd-4243-4a79-8e64-c6f88b7fd92e" class="bulleted-list"><li style="list-style-type:disc">Change algorithm or parameters</li></ul><ul id="4a7934ee-5566-4d47-bd31-5bd2c447a856" class="bulleted-list"><li style="list-style-type:disc">Train specialized model for poor-classes</li></ul><h1 id="386fa14e-25dc-46b3-9cbd-5c066103ec03" class="">🔥 FHIR (with Vijay)</h1><p id="ee8466a1-e2a9-46f0-b9fb-0e0388fcc02d" class="">
</p><h2 id="c7976f0b-8e20-4482-9d81-bcd26ceee3c8" class="">Overview</h2><p id="397b1e00-238c-4348-80bb-d098cefe2c04" class="">FHIR (Fast Healthcare Interoperability Resources) is a standard describing data formats and elements (known as &quot;resources&quot;) and an application programming interface (API) for exchanging electronic health records (EHR). The standard is developed by Health Level Seven International (HL7), aimed at <strong>making healthcare information sharing quicker</strong>, easier, and more effective for everyone involved. FHIR is designed to enable healthcare information to be available, discoverable, and understandable globally, and to support a wide range of applications, including:</p><ul id="8ee53fd4-b49e-44cc-9921-f089ea90e5c5" class="bulleted-list"><li style="list-style-type:disc">Electronic Health Record (EHR) systems</li></ul><ul id="57192cb1-0345-4447-b28a-2686f061a814" class="bulleted-list"><li style="list-style-type:disc">Data sharing between healthcare providers</li></ul><ul id="0c694665-4f52-4b45-8d31-89bae98f5f27" class="bulleted-list"><li style="list-style-type:disc">Mobile apps, cloud communications, and data analysis applications in clinical and research settings</li></ul><p id="c9b56e7e-d5ea-40e7-8d1d-1cb552c06fd2" class="">FHIR builds on previous data standards from HL7, but it is easier to implement because it uses a modern web-based suite of API technology, including a protocol for data exchange (HTTP) and formats for data representation (XML, JSON). Its modular approach allows systems to interact with each other even if they were developed independently, facilitating better and more accessible healthcare worldwide.</p><p id="a3601363-fef1-4509-ab95-b385ac98d97e" class="">
</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="6cf603f9-e8c3-47d7-b03e-29430fbe5db1"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%"><mark class="highlight-default">The primary source of truth for FHIR Resources can be found here </mark><mark class="highlight-default"><a href="https://www.hl7.org/fhir/resourcelist.html">https://www.hl7.org/fhir/resourcelist.html</a></mark></div></figure><p id="ec19eda3-4af2-4623-8e77-2bf57331ef33" class="">
</p><p id="4a081016-a589-46f8-89b7-7d6f1e5e0ee9" class="">
</p><h2 id="414f9e67-4ecc-4cbc-bcde-8bacb2cea99e" class="">Why FHIR  for Data Science?</h2><h3 id="29d5bb5d-1043-4bf8-aa0f-5af5659a2663" class=""><strong>Standardizes Data Formats</strong></h3><p id="33db4476-9476-4791-8cc5-abc12f54274e" class="">FHIR provides a consistent framework for healthcare information, simplifying data integration and exchange across various systems.</p><h3 id="08c46a7f-200b-4409-80f5-de85ad2a386b" class=""><strong>Facilitates Data Analysis</strong></h3><p id="5d8c2b9f-8460-4178-824f-5027cba6ce3a" class="">With standardized data, healthcare data scientists can more effectively analyze and derive insights, leading to improved patient care and operational efficiencies.</p><h3 id="041bcc42-a076-456e-85d9-4b2f39cab0d0" class=""><strong>Supports Innovation</strong></h3><p id="be51c886-1b40-4cbe-9cc4-1845d51c4ade" class="">FHIR enables easier access to data, fostering innovation in healthcare technologies, research, and development.</p><p id="e81f5b8c-67d1-4f02-aa12-a42aa5edfe82" class="">
</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="1d30b792-aa5f-4dc6-8405-e550d8507309"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%">As a data scientist, mastering FHIR equips you with the flexibility to thrive in various dynamic settings.</div></figure><p id="556b2546-735c-47c9-b251-77541ba2fb16" class="">
</p><p id="172feb5b-2e53-4450-a9e9-f5ed68f142f0" class="">
</p><h2 id="2282bcec-75c4-4283-808a-155e8b044f7d" class="">A few core FHIR concepts</h2><h3 id="97a273db-4803-4e98-a8a2-8bd50cf56dc2" class=""><strong>FHIR Resources</strong></h3><p id="e9787243-8a78-4536-be18-5513e803bf57" class="">Fundamental building blocks in FHIR, representing data elements and structures for healthcare information, such as patients, encounters, and clinical observations. Each resource defines a set of data elements and their relationships, enabling interoperability between systems.</p><h3 id="7f48f9c4-052d-4ab8-8edd-419981654d97" class=""><strong>FHIR Codes</strong></h3><p id="b6608107-8c4c-4e10-916d-74f0d4e313a5" class="">A system of codes used within FHIR resources to represent data consistently, such as diagnosis codes, medication codes, and procedure codes. These codes facilitate the standardized representation and interpretation of healthcare information across different systems.</p><h3 id="65599366-1cd5-4188-a5fb-0ee5d06ade8e" class=""><strong>FHIR Extensions</strong></h3><p id="37bbfdd5-9b66-4fc0-b1bd-7d7f931a25ce" class="">Mechanisms that allow for the customization and extension of FHIR resources to meet specific needs not covered by the standard model. Extensions enable the addition of new data elements to existing resources, ensuring flexibility and adaptability to various healthcare scenarios.</p><p id="0066493a-c428-4384-b5da-7a2766e446c4" class="">
</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="f021f02f-09e3-4dfd-94a8-1c5e78c99de5"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%">FHIR is a <strong>global</strong> standard which means it’s designed to be very flexible</div></figure><p id="e837cc08-1ddf-4e91-9999-d7c1555248f9" class="">
</p><h2 id="a4c4a85e-598c-4cc5-b6bc-d9aa6bfa17f8" class="">FHIR connects the patient and clinical journey </h2><p id="bb830008-62c7-4928-8a92-57e24ca2f9b0" class="">
</p><figure id="aad3ca2e-461d-437b-a690-f8692d775d21" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/Screenshot_2024-02-04_at_8.06.21_PM.png"><img style="width:2472px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/Screenshot_2024-02-04_at_8.06.21_PM.png"/></a></figure><p id="c21105eb-a2eb-4194-8f21-77dcb2a19c60" class="">
</p><p id="b7987eda-2ff0-484d-a948-db33450cfdc8" class="">
</p><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="f13c11a5-0487-4070-9ad2-336de08f2688"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%">FHIR touches all parts of the clinical/patient journey. This can include genomic, clinical and non clinical data about the patient.</div></figure><p id="04515d77-f1f3-40df-be91-a70b96db90e7" class="">
</p><p id="6838c861-7006-4a7a-834a-19848be32372" class="">
</p><h2 id="10035aa0-7588-4326-a26a-b7dff92711fd" class="">FHIR and Data Science</h2><h3 id="4af37b8f-8785-4a43-8d17-464cba7d6715" class=""><strong>Data Collection Process</strong></h3><p id="6a582648-3cc5-4fd7-ab7b-62ea7804a12f" class="">Utilize APIs like FHIR to extract patient data from EHR systems, employ web scraping to gather relevant health information from online sources, and integrate data from wearable devices through their respective SDKs or APIs for a comprehensive dataset.</p><h3 id="46f07b4b-6d5d-44a9-ad2d-917c26f72484" class=""><strong>Running Data Analysis</strong></h3><p id="6340e6a2-e692-4319-841a-507854037580" class="">Implement Python libraries such as Pandas for data manipulation, Scikit-learn for machine learning model development, and Matplotlib for data visualization to uncover insights, predict outcomes, and identify trends from the collected data.</p><h3 id="8cfd01b2-ff5e-47d8-8473-b9e69ecfeb6a" class=""><strong>Applying in Real-world</strong></h3><p id="76ea4917-a1eb-4fdc-a2af-452a21c2466e" class="">For instance, develop a predictive model using Scikit-learn to identify patients at risk of chronic diseases based on their historical health data, then use this model to assist healthcare providers in creating personalized treatment plans, enhancing patient care and preventing hospital readmissions.</p><p id="19f99cb0-e755-4020-a006-aa0828349810" class="">
</p><p id="3f521d4e-463b-46fe-bebe-c5f258204a31" class="">
</p><h2 id="5e3fafc5-941f-43c9-b496-f6be4c679567" class="">Python Learning Objective</h2><ul id="969014c9-aecb-404f-bf20-c636f98be371" class="bulleted-list"><li style="list-style-type:disc">Load FHIR data</li></ul><ul id="ffe90534-c6f8-4d2e-aba6-3c18f773a6b3" class="bulleted-list"><li style="list-style-type:disc">Navigate objects</li></ul><ul id="5b08c60e-5240-4b60-8578-5bd0d23a117c" class="bulleted-list"><li style="list-style-type:disc">Read and Update values </li></ul><ul id="3d3a70e2-6465-434f-b734-9c9db4846b07" class="bulleted-list"><li style="list-style-type:disc">Validate FHIR resources</li></ul><h3 id="21e2bd30-26a0-4269-a6ff-318baf446bd7" class="">Install the FHIR Python Package</h3><p id="62b4693e-51e4-47c0-850c-02d0fdba99aa" class=""><a href="https://pypi.org/project/fhir.resources/">https://pypi.org/project/fhir.resources/</a></p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="8b922015-a2e7-46cf-a96a-a9ab7b1b0573" class="code"><code class="language-Shell">pip install fhir.resources</code></pre><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="5fc5af9d-0a41-495c-a944-841f0a7b7a92"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%"><strong>NOTE: </strong>FHIR objects can also represent other species</div></figure><p id="b1825117-257e-44f1-bcd3-4e214510706f" class="">Load a sample FHIR object</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="5e7f4386-d837-4356-afe7-cd8b53de3f7d" class="code"><code class="language-Python">from fhir.resources.patient import Patient
import json

# Load a Patient Resource (an animal!)

# Opening JSON file
f = open(&#x27;./fhir-resources/patient-example-animal.json&#x27;)

# returns JSON object as
# a dictionary

# Load the FHIR Data
fhir_data = json.load(f)
# Create a Patient object from the JSON data
patient = Patient(**fhir_data)

# Extract specific fields
patient_name = patient.name[0].given[0]
species = patient.extension[0].extension[0].valueCodeableConcept.coding[0].display
breed = patient.extension[0].extension[1].valueCodeableConcept.coding[0].display
gender_status = patient.extension[0].extension[2].valueCodeableConcept.coding[0].code

print(f&quot;Patient Name: {patient_name}&quot;)
print(f&quot;Species: {species}&quot;)
print(f&quot;Breed: {breed}&quot;)
print(f&quot;Gender Status: {gender_status}&quot;)</code></pre><h3 id="f1b6cb61-f471-4911-a576-b53b5e2eeef7" class="">Update some fields</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="8ed2a729-eac9-40b7-a318-3be46dd30b43" class="code"><code class="language-Shell"># Update the patient&#x27;s contact number
patient.contact[0].telecom[0].value = &quot;(03) 9999 9999&quot;

# Update the managing organization
patient.managingOrganization.display = &quot;New Veterinary Services&quot;

# Convert back to a FHIR model if needed to send or store
updated_fhir_json = patient.json(indent=2)</code></pre><h3 id="46c8d595-d192-4158-8b48-19dace3a55ac" class="">Check if the object is still valid</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="98294ad9-8e4f-47b2-8b96-c3dd07268a8e" class="code"><code class="language-Shell">is_valid = &#x27;managingOrganization&#x27; in patient.dict()

print(f&quot;Validation Result: {&#x27;Valid&#x27; if is_valid else &#x27;Invalid&#x27;}&quot;)</code></pre><p id="d1482b34-6a7f-43f5-9c01-19b38b116285" class="">
</p><p id="49e1564a-3fa2-4a78-8183-1fcdadbb70ce" class="">
</p><h2 id="20c14caf-399e-410f-b291-0352a3f2793b" class="">FHIR Data Set</h2><ul id="bbf51a35-09ec-4bb0-a0d6-92ad90070ea9" class="bulleted-list"><li style="list-style-type:disc"><a href="https://physionet.org/content/mimic-iv-fhir-demo/2.0/">https://physionet.org/content/mimic-iv-fhir-demo/2.0/</a></li></ul><p id="ac337778-7548-44a6-871e-4310b4c5ddb6" class="">
</p><p id="ac457cf7-1e40-4d5c-92cc-11e68cf0ddbc" class="">
</p><h2 id="25fb65ad-7abb-461a-96ec-36108e95ceb3" class="">Patient Resource Example</h2><h3 id="49492321-f819-43ea-a906-1aaba4d6fc67" class="">Schema</h3><figure id="1ff7224a-625f-40d0-8e11-8186f0804138" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/Screenshot_2024-02-03_at_7.11.18_PM.png"><img style="width:2256px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/Screenshot_2024-02-03_at_7.11.18_PM.png"/></a></figure><h3 id="0ef5cd3e-1e17-4411-91e4-5482ef126da1" class="">Raw Data: Deceased Patient</h3><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="f2745ec3-5c67-4c4c-8315-5d8e21bfd836" class="code"><code class="language-JSON" style="white-space:pre-wrap;word-break:break-all">{
  &quot;resourceType&quot; : &quot;Patient&quot;,
  &quot;id&quot; : &quot;pat3&quot;,
  &quot;meta&quot; : {
    &quot;versionId&quot; : &quot;1&quot;
  },
  &quot;text&quot; : {
    &quot;status&quot; : &quot;generated&quot;,
    &quot;div&quot; : &quot;&lt;div xmlns=\&quot;http://www.w3.org/1999/xhtml\&quot;&gt;&lt;p style=\&quot;border: 1px #661aff solid; background-color: #e6e6ff; padding: 10px;\&quot;&gt;&lt;b&gt;Simon Notsowell (OFFICIAL)&lt;/b&gt; male, DoB: 1982-01-23 ( Medical record number:\u00a0123457\u00a0(use:\u00a0USUAL))&lt;/p&gt;&lt;hr/&gt;&lt;table class=\&quot;grid\&quot;&gt;&lt;tr&gt;&lt;td style=\&quot;background-color: #f3f5da\&quot; title=\&quot;Record is active\&quot;&gt;Active:&lt;/td&gt;&lt;td&gt;true&lt;/td&gt;&lt;td style=\&quot;background-color: #f3f5da\&quot; title=\&quot;Known status of Patient\&quot;&gt;Deceased:&lt;/td&gt;&lt;td colspan=\&quot;3\&quot;&gt;2015-02-14T13:42:00+10:00&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=\&quot;background-color: #f3f5da\&quot; title=\&quot;Alternate names (see the one above)\&quot;&gt;Alt. Name:&lt;/td&gt;&lt;td colspan=\&quot;3\&quot;&gt;Jock (NICKNAME)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=\&quot;background-color: #f3f5da\&quot; title=\&quot;Patient Links\&quot;&gt;Links:&lt;/td&gt;&lt;td colspan=\&quot;3\&quot;&gt;&lt;ul&gt;&lt;li&gt;Managing Organization: &lt;a href=\&quot;organization-example-gastro.html\&quot;&gt;Organization/1: ACME Healthcare, Inc&lt;/a&gt; &amp;quot;Gastroenterology&amp;quot;&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;&quot;
  },
  &quot;identifier&quot; : [{
    &quot;use&quot; : &quot;usual&quot;,
    &quot;type&quot; : {
      &quot;coding&quot; : [{
        &quot;system&quot; : &quot;http://terminology.hl7.org/CodeSystem/v2-0203&quot;,
        &quot;code&quot; : &quot;MR&quot;
      }]
    },
    &quot;system&quot; : &quot;urn:oid:0.1.2.3.4.5.6.7&quot;,
    &quot;value&quot; : &quot;123457&quot;
  }],
  &quot;active&quot; : true,
  &quot;name&quot; : [{
    &quot;id&quot; : &quot;n1&quot;,
    &quot;use&quot; : &quot;official&quot;,
    &quot;family&quot; : &quot;Notsowell&quot;,
    &quot;given&quot; : [&quot;Simon&quot;]
  },
  {
    &quot;id&quot; : &quot;n2&quot;,
    &quot;use&quot; : &quot;nickname&quot;,
    &quot;given&quot; : [&quot;Jock&quot;]
  }],
  &quot;gender&quot; : &quot;male&quot;,
  &quot;birthDate&quot; : &quot;1982-01-23&quot;,
  &quot;deceasedDateTime&quot; : &quot;2015-02-14T13:42:00+10:00&quot;,
  &quot;managingOrganization&quot; : {
    &quot;reference&quot; : &quot;Organization/1&quot;,
    &quot;display&quot; : &quot;ACME Healthcare, Inc&quot;
  }
}</code></pre><h3 id="83fe1de1-72c3-4dc3-bdf0-991e145b8669" class="">Get all the specs from <a href="https://hl7.org/fhir/resourcelist.html">https://hl7.org/fhir/resourcelist.html</a></h3><figure id="d956365c-aaa0-421c-ac4e-6d399448efca" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/Screenshot_2024-02-03_at_7.12.33_PM.png"><img style="width:2462px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/Screenshot_2024-02-03_at_7.12.33_PM.png"/></a></figure><figure id="529ec6af-5a82-491b-bd57-9bea029b51b9" class="link-to-page"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/Depression%20&amp;%20anxiety%20with%20FHIR%20529ec6af5a82491bbd579bea029b51b9.html"><span class="icon">🧑‍🚒</span>Depression &amp; anxiety with FHIR</a></figure><h1 id="61ab6beb-7e82-42f2-a174-21b8f9f0d4bc" class="">Process for model training</h1><h2 id="d5e48523-fd0d-48c3-852c-30ed413623ca" class="">Loss &amp; accuracy over epochs</h2><p id="78adf91d-fec8-4e85-94f5-13a55fa388ff" class="">When training machine learning models, it&#x27;s crucial to understand how loss and accuracy metrics evolve over multiple epochs. </p><ul id="d53a6c66-aaab-42e5-b26e-22a9a7875e27" class="bulleted-list"><li style="list-style-type:disc"><strong>epoch:</strong> One full pass through the training data, often broken down into smaller <strong>steps</strong></li></ul><ul id="8ace46c8-d948-464f-bd98-790671422f1d" class="bulleted-list"><li style="list-style-type:disc"><strong>loss:</strong> Quantifies the difference between the predicted output and the actual target values<blockquote id="7983510e-8425-4c19-94a8-875380113b2f" class="">In essence, it represents the error the model is making, and during training, the goal is to minimize this error:</blockquote></li></ul><ul id="35e9679a-a4e1-40a9-95b0-1eb8412cbab2" class="bulleted-list"><li style="list-style-type:disc"><strong>accuracy: </strong>Model evaluation metric as defined above (# correct)/(# total)<blockquote id="3bda1612-150f-4d71-a27b-6d56605c82c2" class="">For certain models, it may be possible to specify different evaluation metrics</blockquote></li></ul><p id="c40b03d8-4784-4abc-8082-44601ad0dbe9" class="">Monitoring these metrics can provide insights into the model&#x27;s learning behavior. By observing these trends, we can identify potential challenges such as overfitting or under-fitting and how we might address those issues. We will visualize this with a graph depicting the training and validation loss/accuracy curves during the “Hands-on practice” section.</p><h2 id="9b6cfa67-b2e8-4a49-bcec-313b60e54009" class="">Hyperparameters</h2><p id="e933b337-0ad7-4200-911e-14e439903b3b" class="">Also written as “hyper-parameters”, these are the arguments passed into models that may be adjusted. <strong>They are set prior to training and adjusting them can significantly impact the model&#x27;s behavior.</strong></p><p id="42f224c4-cbd6-442c-b276-e64d12aa5093" class="">Hyperparameters play a critical role in shaping the behavior and performance of machine learning models. Examples include learning rates, regularization strengths, and tree depths. Proper tuning of hyperparameters is essential for optimizing model performance.</p><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0">Examples of hyperparameters</summary><div class="indented"><ul id="41a5452f-c37e-414a-b06e-0b4a19db560d" class="bulleted-list"><li style="list-style-type:disc"><strong>Learning Rate (LR)</strong><ul id="6f2eeb7e-98c7-4f17-b28e-d6a32edb03f2" class="bulleted-list"><li style="list-style-type:circle"><strong>Applicable Models:</strong> Neural Networks, Gradient Boosted Trees, Support Vector Machines.</li></ul><ul id="18e88eb4-6b61-440c-9f67-4dbfb23ca1bc" class="bulleted-list"><li style="list-style-type:circle"><strong>Description:</strong> Controls the step size during optimization. Too high can lead to overshooting, too low can result in slow convergence.</li></ul></li></ul><ul id="687762d5-4a69-4a12-8e81-ffdf6f63f438" class="bulleted-list"><li style="list-style-type:disc"><strong>Regularization Strength</strong><ul id="e5aa6249-66ac-440a-a2b0-8399a57fd734" class="bulleted-list"><li style="list-style-type:circle"><strong>Applicable Models:</strong> Linear Regression, Logistic Regression.</li></ul><ul id="6e6e5396-2f56-4754-8c05-1fc5954a4436" class="bulleted-list"><li style="list-style-type:circle"><strong>Description:</strong> Balances fitting the training data well while avoiding overfitting. Higher values increase regularization.</li></ul></li></ul><ul id="41c511fc-4657-4ea7-8bf3-848b45d995cf" class="bulleted-list"><li style="list-style-type:disc"><strong>Tree Depth (Max Depth)</strong><ul id="ad841aba-aed6-4daf-8507-9e06380c2838" class="bulleted-list"><li style="list-style-type:circle"><strong>Applicable Models:</strong> Decision Trees, Random Forest, Gradient Boosted Trees.</li></ul><ul id="7851b029-8201-45ff-83aa-dccd1cf01b4a" class="bulleted-list"><li style="list-style-type:circle"><strong>Description:</strong> Limits the maximum depth of individual trees, preventing overfitting.</li></ul></li></ul><ul id="bac6be83-0186-4c2d-9795-ef3008a27aed" class="bulleted-list"><li style="list-style-type:disc"><strong>Number of Estimators (Trees)</strong><ul id="5728b1a6-f1aa-4b5c-93cf-65d5ea4806fd" class="bulleted-list"><li style="list-style-type:circle"><strong>Applicable Models:</strong> Random Forest, Gradient Boosted Trees.</li></ul><ul id="0763a80c-add6-4239-8eec-a1aa6359bdd7" class="bulleted-list"><li style="list-style-type:circle"><strong>Description:</strong> Determines how many trees are built in an ensemble model.</li></ul></li></ul><ul id="92a83f14-4c04-43bb-abef-b9368260acfa" class="bulleted-list"><li style="list-style-type:disc"><strong>Batch Size</strong><ul id="2168a289-467d-4c79-8b9a-ec17fea54415" class="bulleted-list"><li style="list-style-type:circle"><strong>Applicable Models:</strong> Neural Networks.</li></ul><ul id="b669c056-dcce-44f8-acd8-fa3fa016223b" class="bulleted-list"><li style="list-style-type:circle"><strong>Description:</strong> Number of training examples utilized in one iteration. Larger batches may speed up training but require more memory.</li></ul></li></ul><ul id="36ae048c-0263-4e2c-92f1-d1844a880c79" class="bulleted-list"><li style="list-style-type:disc"><strong>Dropout Rate</strong><ul id="b2c9b758-9d91-439b-ae63-a4781cf20e1a" class="bulleted-list"><li style="list-style-type:circle"><strong>Applicable Models:</strong> Neural Networks.</li></ul><ul id="643ef18b-8222-44cc-ab55-60e739b11d03" class="bulleted-list"><li style="list-style-type:circle"><strong>Description:</strong> Fraction of input units to drop during training. Prevents overfitting by introducing redundancy.</li></ul></li></ul><ul id="1176cdb1-dbf9-4d75-b0dc-48155b38a057" class="bulleted-list"><li style="list-style-type:disc"><strong>Kernel Size</strong><ul id="6ab93ebf-b7f3-4f3a-876f-ce4942223c3c" class="bulleted-list"><li style="list-style-type:circle"><strong>Applicable Models:</strong> Convolutional Neural Networks (CNN).</li></ul><ul id="0da00b02-179c-43e6-a1a8-d52a5f10406f" class="bulleted-list"><li style="list-style-type:circle"><strong>Description:</strong> Specifies the size of the convolutional kernel in CNN layers.</li></ul></li></ul><ul id="0c89872b-9da5-4c8f-9bc1-13c0a687d72f" class="bulleted-list"><li style="list-style-type:disc"><strong>C (Cost) in SVM</strong><ul id="a5f6e9a6-111c-4d48-866a-9164f36acc38" class="bulleted-list"><li style="list-style-type:circle"><strong>Applicable Models:</strong> Support Vector Machines.</li></ul><ul id="5f5e4249-7b17-470c-a3f5-2265ef31d74a" class="bulleted-list"><li style="list-style-type:circle"><strong>Description:</strong> Trade-off between smooth decision boundaries and classifying training points correctly.</li></ul></li></ul><ul id="a944c152-7d1c-4939-bd94-152e58d29af2" class="bulleted-list"><li style="list-style-type:disc"><strong>Alpha</strong><ul id="ad59b047-0d37-4dc1-bc4c-73e7a853f4b1" class="bulleted-list"><li style="list-style-type:circle"><strong>Applicable Models:</strong> Ridge Regression.</li></ul><ul id="7b38c2ec-98e2-40d9-a8ef-767a6d5323e8" class="bulleted-list"><li style="list-style-type:circle"><strong>Description:</strong> Regularization term in Ridge Regression to control the influence of high-degree polynomial terms.</li></ul></li></ul><ul id="c219ca3a-88b0-4747-9d04-f33f9646c7d4" class="bulleted-list"><li style="list-style-type:disc"><strong>Min Samples Split</strong><ul id="9f9babbb-9644-40eb-b1cf-6eb79a929aba" class="bulleted-list"><li style="list-style-type:circle"><strong>Applicable Models:</strong> Decision Trees, Random Forest.</li></ul><ul id="0ef19d3f-6a56-4b5c-b48f-0e6e891f7dee" class="bulleted-list"><li style="list-style-type:circle"><strong>Description:</strong> The minimum number of samples required to split an internal node.</li></ul></li></ul></div></details><h2 id="85da3a8f-fabe-4070-951e-b45225b7f71f" class="">Model showdown process</h2><p id="7cfb90d9-7fd9-4ccd-9dfe-2b60f7074687" class="">We want to be rigorous when training multiple models and choosing a winner so, like in any research project, we should pre-define the methodology before beginning.</p><details open=""><summary style="font-weight:600;font-size:1.25em;line-height:1.3;margin:0">Example model selection flow</summary><div class="indented"><ul id="80945305-0402-4e7d-9053-25567cc0f4d0" class="bulleted-list"><li style="list-style-type:disc"><strong>Load data</strong><ul id="fa387e0e-7f72-41f4-aee5-2c468d454feb" class="bulleted-list"><li style="list-style-type:circle"><strong>Import:</strong> raw data into a performance layer (e.g., database)</li></ul><ul id="7f300935-5bc4-4d36-a0c6-02e77667f52e" class="bulleted-list"><li style="list-style-type:circle"><strong>Validate:</strong> import matches data dictionary</li></ul><ul id="17872999-30ac-40c0-8c86-ac3ba1f61ea0" class="bulleted-list"><li style="list-style-type:circle"><strong>Store:</strong> in a persistent format (e.g., parquet)</li></ul></li></ul><ul id="9758b6cc-4e02-411d-abef-18052fb911b6" class="bulleted-list"><li style="list-style-type:disc"><strong>Exploratory data analysis</strong><ul id="f87fac13-08c6-4333-9e16-a1027a4e5754" class="bulleted-list"><li style="list-style-type:circle"><strong>Autoprofile: </strong>Utilize autoprofiling (via <code>ydata-profiling</code>  or similar)<ul id="62da67b2-26b6-4918-a4e6-9fe6dd924ea2" class="bulleted-list"><li style="list-style-type:square"><strong>Column value counts:</strong> Identify the distribution of values in each column</li></ul><ul id="e3327324-4664-43de-80bc-73a9f0969955" class="bulleted-list"><li style="list-style-type:square"><strong>Numerical distribution: </strong>Measures of center and spread</li></ul></li></ul><ul id="f074e52c-5810-4dae-8b3d-9756f22c30bd" class="bulleted-list"><li style="list-style-type:circle"><strong>Autoprofile, split by Outcome/Class:</strong> Generate separate autoprofiles by segment</li></ul><ul id="903728a2-55b8-420d-a091-e677329cf995" class="bulleted-list"><li style="list-style-type:circle"><strong>Identify problem variables:</strong> Identify high missing values, unusual distributions, or potential data quality issues</li></ul></li></ul><ul id="1b078d1c-4a08-4437-bf90-05b2f106e8bf" class="bulleted-list"><li style="list-style-type:disc"><strong>Transform</strong><ul id="d6048df4-87f8-4bd1-afd9-9517fc11247f" class="bulleted-list"><li style="list-style-type:circle"><strong>Clean up problem variables:</strong> Address missing values, outliers, or any other issues identified during exploratory analysis</li></ul><ul id="248b5a48-be67-4b42-b595-925d94d25274" class="bulleted-list"><li style="list-style-type:circle"><strong>Recode categories:</strong> Recode categorical variables as discussed earlier</li></ul><ul id="aaabf465-bb0f-4c09-9be2-e58b77fdd6d3" class="bulleted-list"><li style="list-style-type:circle"><strong>Manual feature engineering:</strong> Use subject-matter expertise to combine/transform variables</li></ul><ul id="6cfbaf81-5f17-48d6-8378-d85d4dc6e499" class="bulleted-list"><li style="list-style-type:circle"><strong>Automated feature engineering:</strong> Use automated feature engineering tools (e.g., <code>featuretools</code> )</li></ul><ul id="1b95286a-dbd5-4430-95a9-20d587432910" class="bulleted-list"><li style="list-style-type:circle"><strong>Statistical feature engineering:</strong> Utilize self-organizing maps, clustering, principle component analysis, etc. to </li></ul></li></ul><ul id="3e5179ab-08da-4178-a2f5-38245757a937" class="bulleted-list"><li style="list-style-type:disc"><strong>Model selection</strong><ul id="b9a228d6-5457-4c42-b092-22e2d8683046" class="bulleted-list"><li style="list-style-type:circle"><strong>Reserve validation set:</strong> create a validation set that will be excluded from training/testing</li></ul><ul id="d23a781b-3a01-4549-974f-3b2f5d630bee" class="bulleted-list"><li style="list-style-type:circle"><strong>Evaluation criteria:</strong> Define evaluation metrics based on the specifics of the problem being addressed</li></ul><ul id="88e9c470-f86a-4df0-ab3d-c2f8fa02cf2c" class="bulleted-list"><li style="list-style-type:circle"><strong>Candidate models:</strong> Which models should be included in the “showdown” based upon the type of problem and data available</li></ul><ul id="c38da351-6d7a-4a46-b7d8-41c2292e0ef0" class="bulleted-list"><li style="list-style-type:circle"><strong>Hyperparameter tuning: </strong>Search for good hyperparameters for applicable models, noting that at this stage we are only looking for decent approximations rather than optimal </li></ul><ul id="9f482d3a-db05-4e18-b375-840b39571fd9" class="bulleted-list"><li style="list-style-type:circle"><strong>Crossfold training:</strong> Assess model performance robustness across randomized train/test subsets. Create a random train/test split for each round and that same split across all models that round</li></ul><ul id="d5a2fcf9-87c2-47c3-b3b9-163c2eecc981" class="bulleted-list"><li style="list-style-type:circle"><strong>Distribution on unknown class:</strong> Examine how well models generalize to the unknown class</li></ul><ul id="920e59ea-83f3-4f1b-8615-08e3fd8049ae" class="bulleted-list"><li style="list-style-type:circle"><strong>Evaluate &amp; select winner:</strong> Evaluate model performance on the validation set and select the best-performing model</li></ul><ul id="8f49e33b-71d5-4f6b-9e2c-9b023960abbf" class="bulleted-list"><li style="list-style-type:circle"><strong>Feature importance:</strong> Analyze feature importance scores from different models</li></ul></li></ul><ul id="2e335906-d289-407a-9d7d-0d25b1b57f0c" class="bulleted-list"><li style="list-style-type:disc"><strong>Document! Document! Document! </strong><ul id="519730aa-6fc9-49f8-9a3b-e39200bd2153" class="bulleted-list"><li style="list-style-type:circle"><strong>Process: </strong>What did you do and why</li></ul><ul id="a8f17ad6-20b8-4e1d-bb1b-e71edfcf6d22" class="bulleted-list"><li style="list-style-type:circle"><strong>Trade-offs:</strong> Which choices were made, what would be better/worse if you had made others</li></ul><ul id="ea78a068-5bb5-4eab-84f3-4e51e764d531" class="bulleted-list"><li style="list-style-type:circle"><strong>Technical information:</strong> Anything necessary to reproduce your training</li></ul><ul id="87da2e4b-f9b4-4e04-ba12-61b2bb6f86f4" class="bulleted-list"><li style="list-style-type:circle"><strong>Results</strong>: (<em>duh</em>)</li></ul></li></ul></div></details><h2 id="de4721bf-f032-41b1-823b-9236e95311d6" class="">Tips</h2><ul id="9e964df7-82e0-4f28-a372-a0e5d69591d8" class="bulleted-list"><li style="list-style-type:disc"><strong>Start with &quot;babies&quot;</strong>: Start with smaller, simpler models to identify issues early and streamline the debugging process.</li></ul><ul id="138a84c9-8bac-4ad1-b46c-5fe011942f62" class="bulleted-list"><li style="list-style-type:disc"><strong>Use validation sets</strong>: A separate validation set allows you to evaluate model performance during training and prevent overfitting</li></ul><ul id="e136f766-7787-48f4-8a9c-cfbdf4352a17" class="bulleted-list"><li style="list-style-type:disc"><strong>Early stopping</strong>: It is possible to halt training when improvements on the validation set plateau, preventing overfitting by stopping when loss increments fall below a threshold.</li></ul><ul id="d75adb64-3e16-4882-81c8-eace8e628e9b" class="bulleted-list"><li style="list-style-type:disc"><strong>Logging and monitoring</strong>: Log key metrics and monitor them during training, either through log files, print statements, or tools like TensorBoard for real-time visualization</li></ul><ul id="37479e71-4961-4f76-bb97-ffd9708442bf" class="bulleted-list"><li style="list-style-type:disc"><strong>Document :all_the_things:</strong>: Clear documentation, including hyper-parameters and model architecture, are the only way to make your models reproducible and to collaboratively troubleshoot.</li></ul><ul id="2ca9867d-0ade-4cbb-8d82-37fd22d7801b" class="bulleted-list"><li style="list-style-type:disc"><strong>Cross-Validation</strong>: Cross-validation (train/test on random subsets) is important for obtaining a robust estimate of model performance, particularly with limited data.</li></ul><h1 id="e155b656-c4bb-4848-af3f-96802548be73" class="">🏋️ Hands-on practice</h1><h2 id="161b2030-71e0-4335-93b9-c6b80d51c153" class="">Which animal is this?</h2><p id="e8ce2a0b-30ae-4d9e-90c1-6c1b7f1264d2" class="">Adapted from Google Keras code example <a href="https://keras.io/examples/vision/image_classification_from_scratch/">Image classification from scratch</a>. We’ll try to classify dogs vs cats vs pandas:</p><div id="bd885ed9-53b7-4dc6-9294-8517a7163395" class="column-list"><div id="5823a84b-11ef-4fee-af77-6792a544e752" style="width:33.33333333333333%" class="column"><figure id="f8d645fe-cd71-4362-8e7c-c69afb469e85" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/dogs_00013.jpg"><img style="width:499px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/dogs_00013.jpg"/></a></figure></div><div id="a6056ae6-fda9-4f6c-b07b-1a5a85ed48e5" style="width:33.33333333333333%" class="column"><figure id="a5534927-1407-48c5-a011-41f36629fb72" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/cats_00016.jpg"><img style="width:499px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/cats_00016.jpg"/></a></figure></div><div id="b5ae8db7-baa3-483b-b67f-8779cdb1f108" style="width:33.33333333333333%" class="column"><figure id="38c69b2e-c948-4887-b42f-9ffbfe166a80" class="image"><a href="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/panda_00001.jpg"><img style="width:480px" src="Putting%20a%20label%20on%20things%209a7cd21131f24330a84d27123932d201/panda_00001.jpg"/></a></figure></div></div><p id="c96821cb-0087-435d-ab09-ee2eacda58f1" class=""> </p><ol type="1" id="97d02beb-6ac7-4ff3-8867-f1c73c514211" class="numbered-list" start="1"><li>Make sure we’re in a virtual environment</li></ol><ol type="1" id="fb95eefe-32b5-49d2-a790-a84f7db30ec9" class="numbered-list" start="2"><li>Install and load libraries</li></ol><ol type="1" id="06f206c4-c670-4b46-bd3d-6c2c62ba82fd" class="numbered-list" start="3"><li>Download data and split into train, test, and validation</li></ol><ol type="1" id="ac47f130-7e92-44ca-b04b-80c0d66b499b" class="numbered-list" start="4"><li>Define model</li></ol><ol type="1" id="eaa7dcfe-7d97-42e3-bd97-e9ed995a846e" class="numbered-list" start="5"><li>Train model</li></ol><ol type="1" id="2649c2ca-3f3a-4590-889b-84628dcd16a1" class="numbered-list" start="6"><li>Check train/test performance</li></ol><ol type="1" id="6ebcd956-2313-4d66-9953-54b6aeae9d70" class="numbered-list" start="7"><li>Validate against new data</li></ol><h2 id="621dcf39-becf-42f7-860a-9c3735643cae" class="">Classify 0 vs 1 from <code>emnist</code> </h2><h3 id="2d24e98b-60a5-49ee-8028-17c8e46d7455" class="">Setup</h3><p id="f7df16a8-0c98-42b3-bc5e-4bd184941505" class=""><strong>Install/import libraries</strong></p><p id="a93f2f9c-5280-4571-9d50-2ba442b4f296" class="">As usual, remember to use a virtual environment!</p><p id="f768e314-46b1-450e-a2c3-542a5098f684" class=""><strong>Download data</strong></p><p id="d992be93-8291-49d3-b754-03924274382b" class="">The <code>emnist</code> library will download a copy of the dataset</p><h3 id="9e2606cf-fcf7-48d2-ba4c-701001af64b3" class="">Define helper functions, columns, subsets</h3><p id="a55d7798-b7b9-4a51-be42-c0c8a8183c25" class="">It&#x27;s a good idea to preprocess the data to make it easier to work with. You can create subsets of the data for training, validation, and testing. Also, since the labels in the original dataset are encoded as integers, it may be helpful to create a dictionary that maps the integer labels to their corresponding characters.</p><h3 id="bfc606c6-bb2c-4b3b-8515-9a076a45e879" class="">Pre-built models classifying 0/1</h3><ul id="3dfc5c5e-a2f9-4902-b448-cb33983e6d4f" class="bulleted-list"><li style="list-style-type:disc">Logistic regression</li></ul><ul id="9353aed0-0597-4531-9b54-289a28033c86" class="bulleted-list"><li style="list-style-type:disc">RandomForest</li></ul><ul id="d7201fda-a45e-4e67-8731-1f4cbb2b4786" class="bulleted-list"><li style="list-style-type:disc">XGBoost</li></ul><ul id="0b391893-5f7c-46e2-99a0-145f2ca79dc6" class="bulleted-list"><li style="list-style-type:disc">Neural network</li></ul><h3 id="af0c14e7-a7cd-4094-a2ee-b21ab796b463" class="">Evaluate/compare model performance</h3><ul id="c17e3409-9dda-416a-9152-7f230760f77d" class="bulleted-list"><li style="list-style-type:disc">Confusion matrix: A table that shows the number of true positives, true negatives, false positives, and false negatives for a binary classification problem.</li></ul><ul id="198585e1-2401-4d52-9337-04bc11e6905a" class="bulleted-list"><li style="list-style-type:disc">Accuracy: The proportion of correct predictions over the total number of predictions.</li></ul><ul id="c58bd914-b2fb-470f-83b7-595248685097" class="bulleted-list"><li style="list-style-type:disc">Precision: The proportion of true positives over the total number of positive predictions.</li></ul><ul id="c3c668ad-0f4b-4aa5-a86a-598a4226595f" class="bulleted-list"><li style="list-style-type:disc">Recall: The proportion of true positives over the total number of actual positives.</li></ul><ul id="d1428478-8429-4976-80da-bec30627c34b" class="bulleted-list"><li style="list-style-type:disc">F1 score: The harmonic mean of precision and recall, which balances both metrics and gives equal weight to both.</li></ul><h1 id="1754cbe1-2186-48cd-8592-021021da8b92" class="">🦾 Exercise</h1><h2 id="b38f9eea-6024-441d-88c7-d013d0a8adef" class="">1. Classify all symbols</h2><h3 id="feb3f2fc-92fa-40b2-83d8-c3da19af4ff8" class="">Choose a model</h3><p id="d6d600e1-6f5c-438d-be8a-34326a998e04" class="">Your choice of model! Choose wisely…</p><h3 id="83a29a42-fe92-42ec-aa84-8dd9ae87fcf1" class="">Train away!</h3><p id="4f149d87-3fb2-4aa8-bff3-9a9b3d3ca716" class="">Is do you need to tune any parameters? Is the model expecting data in a different format?</p><h3 id="8b7039ee-9eba-4fe4-bc45-8b1815b69ae1" class="">Evaluate the model</h3><p id="31c78a3d-e610-4e92-bb26-16030f33143b" class="">Evaluate the models on the test set, analyze the confusion matrix to see where the model performs well and where it struggles.</p><h3 id="838aa17c-aad5-4fac-868e-85442b970dd5" class="">Investigate subsets</h3><p id="8b5cce0a-0c84-47e7-9521-2b5d15b64c94" class="">On which classes does the model perform well? Poorly? Evaluate again, excluding easily confused symbols (such as &#x27;O&#x27; and &#x27;0&#x27;).</p><h3 id="32c4d52d-af7b-41a2-808f-095d0b6c46c7" class="">Improve performance</h3><p id="1963530c-5ac4-4e91-8ad8-1e6a0866862e" class="">Brainstorm for improving the performance. This could include trying different architectures, adding more layers, changing the loss function, or using data augmentation techniques.</p><p id="b1dcc506-2a00-408f-b547-415b16dd0d6c" class="">
</p><h1 id="33a78d5c-4a53-4b2d-8c0f-cec3b6f5fc8e" class="">🚶‍♀️Self-guided topics</h1><h2 id="5998eae9-4257-4484-9fa6-718918af29a0" class="">Awesome list of applications</h2><ul id="7c8abd7f-3a02-469d-b3fe-94da8cb3351f" class="bulleted-list"><li style="list-style-type:disc"><a href="https://github.com/ritchieng/the-incredible-pytorch">https://github.com/ritchieng/the-incredible-pytorch</a></li></ul><h2 id="63d3615f-54c8-46cd-9854-e180e2683b88" class="">More MNIST</h2><p id="6bbb46d6-af46-4ace-ab66-17aa40b5b8fa" class="">Classifying hand-written digits is the “Hello, World!” of image ML.</p><ul id="c498c788-45d8-414d-850d-84e5ae85c312" class="bulleted-list"><li style="list-style-type:disc">K-means - <a href="https://github.com/sharmaroshan/MNIST-Using-K-means">https://github.com/sharmaroshan/MNIST-Using-K-means</a></li></ul><ul id="c5d0aea8-7cbd-4eca-9bf1-ee93460f2f74" class="bulleted-list"><li style="list-style-type:disc">MNIST, the Hello World of Deep Learning (<a href="https://medium.com/fenwicks/tutorial-1-mnist-the-hello-world-of-deep-learning-abd252c47709">medium</a>)</li></ul><h2 id="97a1b3bf-7e51-43bc-b1ba-b3ce319d06e6" class="">Fashion MNIST</h2><ul id="548a4ce1-0bd4-425c-929e-d4a289a499f5" class="bulleted-list"><li style="list-style-type:disc"><code>torchvision</code> <a href="https://pytorch.org/vision/stable/datasets.html">provides this dataset</a> and is a great tool for image classification</li></ul><ul id="b74742d9-86f4-4afd-b81a-93ec3409082f" class="bulleted-list"><li style="list-style-type:disc"><a href="https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb">Fashion MNIST</a> example using Colab</li></ul><ul id="a2fbf89e-4d5a-4576-a506-f652e22a9925" class="bulleted-list"><li style="list-style-type:disc">TensorFlow - <a href="https://jobcollinsdulo.medium.com/part-one-image-classification-with-tensorflow-python-f92f94121ec1">https://jobcollinsdulo.medium.com/part-one-image-classification-with-tensorflow-python-f92f94121ec1</a></li></ul><ul id="5c36d512-3c22-43cc-a44b-d7ac5e668713" class="bulleted-list"><li style="list-style-type:disc">PyTorch - <a href="https://medium.com/ml2vec/intro-to-pytorch-with-image-classification-on-a-fashion-clothes-dataset-e589682df0c5">https://medium.com/ml2vec/intro-to-pytorch-with-image-classification-on-a-fashion-clothes-dataset-e589682df0c5</a></li></ul><h2 id="67018b5c-b01f-4b32-abfc-74bc8d476174" class="">Tabular data </h2><ul id="cec695cd-9e70-4ce4-b601-18626fed6a27" class="bulleted-list"><li style="list-style-type:disc"><a href="https://github.com/ThisIsJohnnyLau/dirty_data_project">https://github.com/ThisIsJohnnyLau/dirty_data_project</a> (6 datasets for cleaning)</li></ul><ul id="24bc473d-7a3a-4306-8fec-6d94f2a278ef" class="bulleted-list"><li style="list-style-type:disc">Using Unsupervised Learning to optimise Children’s T-shirt Sizing (<a href="https://towardsdatascience.com/using-unsupervised-learning-to-optimise-childrens-t-shirt-sizing-d919d3cbc1f6">towardsdatascience</a>)</li></ul><h2 id="363d7082-6dc4-4ea2-b331-e818ca6cdd11" class="">Panoramic dental x-rays</h2><p id="931a0489-d24c-4a30-a012-0c12bbdfa8d3" class="">Example flow:</p><ul id="02f00a89-7365-4ea4-ab06-cff766bceddd" class="bulleted-list"><li style="list-style-type:disc"><a href="https://github.com/clemkoa/tooth-detection">https://github.com/clemkoa/tooth-detection</a></li></ul><ul id="9dd54f46-d661-4c65-9b33-2abc3b483d23" class="bulleted-list"><li style="list-style-type:disc"><a href="https://github.com/Nirzu97/PROJECT-Dental-Disease-Detection">https://github.com/Nirzu97/PROJECT-Dental-Disease-Detection</a></li></ul><ul id="9ffa10f7-d5ec-40f8-9bbb-70bcdc65dd3b" class="bulleted-list"><li style="list-style-type:disc">X-ray imaging available at the <a href="http://tdd.ece.tufts.edu">Tufts Dental Database</a></li></ul><h2 id="bbf5e9cb-2d29-492e-b5bd-81056992fd32" class="">Data cleaning for images</h2><ul id="0728ef19-89a1-43e2-983d-9dbad9971cda" class="bulleted-list"><li style="list-style-type:disc">Introduction to Image Pre-processing | What is Image Pre-processing? (<a href="https://www.mygreatlearning.com/blog/introduction-to-image-pre-processing/">Great Learning</a>)</li></ul><ul id="110ead3b-7c76-42a4-acdd-31e8c7469607" class="bulleted-list"><li style="list-style-type:disc"><a href="https://github.com/Nirzu97/PROJECT-Dental-Disease-Detection">https://github.com/Nirzu97/PROJECT-Dental-Disease-Detection</a> (see pptx for a good slide on this)</li></ul><h2 id="d5e5d649-b934-490c-bb0d-d777718b2e9a" class="">Publications on X-ray classification</h2><ul id="678d0f79-6160-4565-8f27-d6d270b56ad6" class="bulleted-list"><li style="list-style-type:disc">Supervised and unsupervised language modelling in Chest X-Ray (<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0229963">PLOS ONE</a>)</li></ul><ul id="140eebfb-625a-47b1-928e-b8d273b53dd5" class="bulleted-list"><li style="list-style-type:disc">Unsupervised Clustering of COVID-19 Chest X-Ray Images with a Self-Organizing Feature Map (<a href="https://ieeexplore.ieee.org/document/9184493">IEEE Xplore</a>)</li></ul><ul id="79890320-71ec-417d-8c41-288222cfeeb4" class="bulleted-list"><li style="list-style-type:disc">A benchmark for comparison of dental radiography analysis algorithms (<a href="https://www.sciencedirect.com/science/article/pii/S1361841516000190">ScienceDirect</a>)</li></ul><p id="f9348ea8-7998-443d-9d3b-fd80ef06cde3" class="">
</p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>